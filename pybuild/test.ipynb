{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "aprime=[];bprime=[];aresult=[];rresult=[]\n",
    "\n",
    "limit = int(input('select matrix dimension: '))\n",
    "scope1 = range(0,4*limit)\n",
    "scope2 = range(0,2*limit)\n",
    "\n",
    "a = np.arange(-limit, limit+.5, .5)\n",
    "b = np.arange(-limit, limit+.5, .5)\n",
    "\n",
    "newa = np.delete(a, np.where(a==0))\n",
    "newb = np.delete(b, np.where(b==0))\n",
    "print('a',newa)\n",
    "print('b',newb)\n",
    "\n",
    "for axb in newa:\n",
    "    if abs(axb) > .01:\n",
    "        aprime.append(axb)\n",
    "print('a',aprime)\n",
    "\n",
    "for adivb in newb:\n",
    "    if abs(adivb) >= 1.0001:\n",
    "        bprime.append(adivb)\n",
    "print('b',bprime)\n",
    "\n",
    "aa = np.multiply.outer(aprime,bprime)\n",
    "bb = np.divide.outer(aprime,bprime)\n",
    "\n",
    "aa.tolist()\n",
    "bb.tolist()\n",
    "\n",
    "print('aa',aa)\n",
    "print('bb',bb)\n",
    "\n",
    "\n",
    "\n",
    "for i in scope1:\n",
    "    for g in scope2:\n",
    "        if (((aa[i][g]) + (bb[i][g])) > 0):\n",
    "            aresult.append('ACCEPT')\n",
    "            print(aa[i][g] + bb[i][g])\n",
    "            print('ACCEPT')\n",
    "        else:\n",
    "            rresult.append('REJECT: CONDITON \"B\" - axb + adivb !> 0')\n",
    "            print(aa[i][g] + bb[i][g])\n",
    "            print('REJECT: CONDITON \"B\"')\n",
    "\n",
    "alenght = len(aresult)\n",
    "\n",
    "if alenght > 0:\n",
    "    print('DECISION: ')\n",
    "    print('ACCEPT-  a*b > a/b in all cases')\n",
    "else:\n",
    "    print('REJECT: Results are mixed')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "aprime=[];bprime=[];aresult=[];rresult=[]\n",
    "limit = int(input('select matrix dimension: '))\n",
    "scope1 = range(0,4*limit)\n",
    "scope2 = range(0,2*limit)\n",
    "a = np.arange(-limit, limit+.5, .5)\n",
    "b = np.arange(-limit, limit+.5, .5)\n",
    "newa = np.delete(a, np.where(a==0))\n",
    "newb = np.delete(b, np.where(b==0))\n",
    "print('a',newa)\n",
    "print('b',newb)\n",
    "for axb in newa:\n",
    "    if abs(axb) > .01:\n",
    "        aprime.append(axb)\n",
    "print('a',aprime)\n",
    "\n",
    "for adivb in newb:\n",
    "    if abs(adivb) >= 1.0001:\n",
    "        bprime.append(adivb)\n",
    "print('b',bprime)\n",
    "aa = np.multiply.outer(aprime,bprime)\n",
    "bb = np.divide.outer(aprime,bprime)\n",
    "aa.tolist()\n",
    "bb.tolist()\n",
    "print('aa',aa), \n",
    "print('bb',bb)\n",
    "for i in scope1:\n",
    "    for g in scope2:\n",
    "        if (((aa[i][g]) + (bb[i][g])) > 0):\n",
    "            aresult.append('ACCEPT')\n",
    "            print(aa[i][g] + bb[i][g])\n",
    "            print('ACCEPT')\n",
    "        else:\n",
    "            rresult.append('REJECT: CONDITON \"B\" - axb + adivb !> 0')\n",
    "            print(aa[i][g] + bb[i][g])\n",
    "            print('REJECT: CONDITON \"B\"')\n",
    "alenght = len(aresult)\n",
    "if alenght > 0:\n",
    "    print('DECISION: ')\n",
    "    print('ACCEPT-  a*b > a/b in all cases')\n",
    "else:\n",
    "    print('REJECT: Results are mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = float(input('select matrix dimension: '))\n",
    "results=[];results2=[];results3=[]\n",
    "\n",
    "x = np.arange(-limit,0,1)\n",
    "\n",
    "\n",
    "for ranger in x:\n",
    "    if ranger**2>=0:\n",
    "        results.append(ranger)\n",
    "if len(results) == len(x):\n",
    "    print('A: YES')\n",
    "else:\n",
    "    print('A: NO')\n",
    "\n",
    "for ranger in x:\n",
    "    if ranger-(2*ranger)>0:\n",
    "        results2.append(ranger)\n",
    "if len(results2) == len(x):\n",
    "    print('B: YES')\n",
    "else:\n",
    "    print('B: NO')\n",
    "\n",
    "for ranger in x:\n",
    "    if ranger**2 + ranger**3<0:\n",
    "        results3.append(ranger)\n",
    "if len(results3) == len(x):\n",
    "    print('C: YES')\n",
    "else:\n",
    "    print('C: NO')\n",
    "\n",
    "print(len(results))\n",
    "print(len(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "limit = int(input('select matrix dimension: '))\n",
    "results=[];results2=[];results3=[]\n",
    "\n",
    "x = np.arange(-limit,0,.1)\n",
    "\n",
    "def formula(test1,test2,test3):\n",
    "    for ranger in test1:\n",
    "        if ranger>=0:\n",
    "            results.append(ranger)\n",
    "    if len(results) == len(x):\n",
    "        print('A: YES')\n",
    "    else:\n",
    "        print('A: NO')\n",
    "\n",
    "    for ranger in test2:\n",
    "        if ranger>0:\n",
    "            results2.append(ranger)\n",
    "    if len(results2) == len(x):\n",
    "        print('B: YES')\n",
    "    else:\n",
    "        print('B: NO')\n",
    "\n",
    "    for ranger in test3:\n",
    "        if ranger<0:\n",
    "            results3.append(ranger)\n",
    "    if len(results3) == len(x):\n",
    "        print('C: YES')\n",
    "    else:\n",
    "        print('C: NO')\n",
    "\n",
    "formula((x**2),(x-(2*x)),(x**2+x**3))\n",
    "\n",
    "print(len(results))\n",
    "print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "limit = int(input('select matrix dimension: '))\n",
    "results=[];results2=[];results3=[]\n",
    "\n",
    "x = np.arange(-limit,1,.1)\n",
    "\n",
    "def formula(test1):\n",
    "    for ranger in test1:\n",
    "        if ranger>=0:\n",
    "            results.append(ranger)\n",
    "        if len(results) == len(x):\n",
    "            print('A: YES')\n",
    "        else:\n",
    "            print('A: NO')\n",
    "\n",
    "formula(x**2)\n",
    "\n",
    "for i in results:\n",
    "    print(\"{:.2f}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lim = int(input('Select matrix dimension: '))\n",
    "res1=[];res2=[];dump1=[];dump2=[]\n",
    "\n",
    "x = np.arange(-lim,lim,.1)\n",
    "y = np.arange(-lim,lim,.1)\n",
    "\n",
    "def jumper(disco,rifle):\n",
    "    for ranger in disco:\n",
    "        if ranger > 0:\n",
    "            res1.append(ranger)\n",
    "        else:\n",
    "            dump1.append(ranger)\n",
    "    for ranger in rifle:\n",
    "        if ranger > 0:\n",
    "            res2.append(ranger)\n",
    "        else:\n",
    "            dump2.append(ranger)\n",
    "    if len(dump1) or len(dump2) > 0:\n",
    "        print('Condition 1 and/or condition 2 are < 0')\n",
    "    else:\n",
    "        print('condition 1 or 2 are true')\n",
    "\n",
    "(jumper((x-y),(x**2-y**2)))\n",
    "\n",
    "for i in x:\n",
    "    for o in y:\n",
    "        print(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lim = float(input('Select matrix dimension: '))\n",
    "res1=[];res2=[];jump1=[];jump2=[];dump1=[];dump2=[]\n",
    "\n",
    "x = np.arange(-lim,lim,.5)\n",
    "y = np.arange(-lim,lim,.5)\n",
    "\n",
    "res1.append(x)\n",
    "res2.append(y)\n",
    "\n",
    "print(np.subtract.outer(res1,res2))\n",
    "\n",
    "# for i in res1:\n",
    "#     for j in res2:\n",
    "#         xx=res1[i][j]\n",
    "\n",
    "print(xx)\n",
    "print(j)  \n",
    "print('-------------')\n",
    "print(res1)\n",
    "\n",
    "def jumper(disco,rifle):\n",
    "    for ranger in disco:\n",
    "        if ranger > 0:\n",
    "            jump1.append(ranger)\n",
    "        else:\n",
    "            dump1.append(ranger)\n",
    "        for ranger in rifle:\n",
    "            if ranger > 0:\n",
    "                jump2.append(ranger)\n",
    "            else:\n",
    "                dump2.append(ranger)\n",
    "    if len(dump1) or len(dump2) > 0:\n",
    "        print('Condition 1 and/or condition 2 are < 0')\n",
    "    else:\n",
    "        print('condition 1 or 2 are true')\n",
    "\n",
    "    for i in dump1:\n",
    "        print(x,y)\n",
    "\n",
    "jumper((np.subtract.outer(res1,res2)),(x**2+y**3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lim = float(input('Select matrix dimension: '))\n",
    "res1=[];res2=[];jump1=[];jump2=[];dump1=[];dump2=[]\n",
    "\n",
    "x = np.arange(-lim,lim,1)\n",
    "y = np.arange(-lim,lim,1)\n",
    "\n",
    "xx=np.subtract.outer(x,y)\n",
    "xx.tolist()\n",
    "\n",
    "# def jumper(disco):\n",
    "#     for ranger in disco:\n",
    "#         if ranger > 0:\n",
    "#             jump1.append(ranger)\n",
    "#         else:\n",
    "#             dump1.append(ranger)\n",
    "#     if len(dump1) > 0:\n",
    "#         print('Condition 1 and/or condition 2 are < 0')\n",
    "#     else:\n",
    "#         print('condition 1 or 2 are true')     \n",
    "\n",
    "# jumper(xx)   \n",
    "\n",
    "# print(x)\n",
    "# print(y)\n",
    "\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(f,g,e,x0,N):\n",
    "   x0 = flag(x0)\n",
    "   e = flag(e)\n",
    "   N = int(N)\n",
    "   step = 1\n",
    "   flag = 1\n",
    "   condition = True\n",
    "   while condition:\n",
    "       if g(x0) == 0.0:\n",
    "           print('divide by zero')\n",
    "           break\n",
    "       x1 = x0 - f(x0)/g(x0)\n",
    "       print('iteration %d, x1=%0.6f and f(x0)=%0.6f' % (step,x1,f(x1)))\n",
    "       x0 = x1\n",
    "       step += 1\n",
    "       if step > N:\n",
    "           flag = 0\n",
    "           break\n",
    "       condition = abs(f(x1)) > e\n",
    "   if flag == 1:\n",
    "       print('\\n the required root is 0.8f' %x1)\n",
    "   else:\n",
    "       print('\\n not convergent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "## Matplotlib Sample Code using 2D arrays via meshgrid\n",
    "X = np.arange(-5, 5, 0.25)\n",
    "Y = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X ** 2 + Y ** 2)\n",
    "Z = np.sin(R)\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.set_zlim(-1.01, 1.01)\n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    " \n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.title('Original Code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-20, 20, 1)\n",
    "xlist=[]\n",
    "xlist.append(x)\n",
    "\n",
    "a = float(input(\"select an integer for 'a': \"))\n",
    "b = float(input(\"select an integer for 'b': \"))\n",
    "c = float(input(\"select an integer for 'c': \"))\n",
    "d = int(input(\"Select tangent point: \"))\n",
    "\n",
    "x_vert = -(b/(2*a))\n",
    "y = a*x**2 + b*x + c\n",
    "yy = a*x_vert**2 + b*x_vert + c\n",
    "x_vert_round = round(x_vert, 3)\n",
    "y_vert = yy\n",
    "y_vert_round = round(y_vert,3)\n",
    "print(\"Your discriminant equals: \",x_vert_round)\n",
    "print(f'your vertex is:',x_vert_round,',',y_vert_round)\n",
    "\n",
    "prime = (((a*2)*(x))+b)\n",
    "slope = ((a*2*d)+b)\n",
    "tangent =(20*x)-3\n",
    "\n",
    "tan1=slope*x\n",
    "for x1 in x:\n",
    "    if (x1[d==x1]):\n",
    "        tan2 = ((slope*d) - (slope*x1))\n",
    "        print('point',(x1[d==x1]))\n",
    "        print('stop',(slope*d))\n",
    "        print('point',(slope*x1))\n",
    "tangent1=(tan1-tan2)\n",
    "\n",
    "print('y',y)\n",
    "print(\"tan1\",tan1)\n",
    "print('tan2',tan2)\n",
    "print('tangent',tangent)\n",
    "print('tangent1',tangent1)\n",
    "print('stop',(slope*d))\n",
    "print('point',(slope*x1))\n",
    "\n",
    "\n",
    "plt.ylim(-500,500,50)\n",
    "plt.grid()\n",
    "plt.plot(y)\n",
    "plt.plot(tangent1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base=int(input('Select base value: '))\n",
    "\n",
    "baseval=np.arange(-base,base,.000001)\n",
    "xaxis=[]\n",
    "xaxis.append(baseval)\n",
    "for e in xaxis:\n",
    "    x=e**2\n",
    "plt.plot(baseval,x)\n",
    "plt.show()\n",
    "# print(baseval)\n",
    "# print(x)\n",
    "\n",
    "# print(type(baseval))\n",
    "# print(type(X))\n",
    "\n",
    "xx=13\n",
    "yy=6.5\n",
    "print(y**2//xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = 5\n",
    "\n",
    "# xlist=[]\n",
    "# xlist.append(x)\n",
    "\n",
    "a = float(input(\"select an integer for 'a': \"))\n",
    "b = float(input(\"select an integer for 'b': \"))\n",
    "c = float(input(\"select an integer for 'c': \"))\n",
    "\n",
    "x_vert = -(b/(2*a))\n",
    "y = a*x**2 + b*x + c\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-100, 100, 1)\n",
    "\n",
    "a = float(input(\"select an integer for 'a': \"))\n",
    "b = float(input(\"select an integer for 'b': \"))\n",
    "c = float(input(\"select an integer for 'c': \"))\n",
    "e = int(input('Select an exponent: '))\n",
    "d = int(input('Select tangent point: '))\n",
    "\n",
    "x_vert = -(b/(2*a))\n",
    "y = a*x**e + b*x + c\n",
    "yy = a*x_vert**e + b*x_vert + c\n",
    "x_vert_round = round(x_vert, 3)\n",
    "y_vert = yy\n",
    "y_vert_round = round(y_vert,3)\n",
    "print(\"Your discriminant equals: \",x_vert_round)\n",
    "print(f'your vertex is:',x_vert_round,',',y_vert_round)\n",
    "\n",
    "prime = (((a*d)*(x**(e-1)))+b)\n",
    "slope = (((a*e)*(d**(e-1)))+b)\n",
    "tangent =(28*x)-35\n",
    "\n",
    "tan1=slope*x\n",
    "\n",
    "for x1 in x:\n",
    "    if x1==(x1[d==x1]):\n",
    "        tan2=x1\n",
    "        print('x1:',tan2)\n",
    "        \n",
    "\n",
    "for y1 in x:\n",
    "    if y1==(y1[d==y1]):\n",
    "        y1=a*d**e+b*d+c\n",
    "        tangent1=(tan1-((slope*d)-y1))\n",
    "        print('y1:',y1)\n",
    "        print('slope:',slope)\n",
    "        \n",
    "\n",
    "print('m*x:',(slope*d))\n",
    "print('f(x):',y)\n",
    "print('tangent:',tangent1)\n",
    "\n",
    "plt.ylim(-500,500,50)\n",
    "plt.grid()\n",
    "plt.plot(y)\n",
    "plt.plot(tangent1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wston\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:24: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  out = s.groupby(level='Date').apply(add_ewm)\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:24: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  out = s.groupby(level='Date').apply(add_ewm)\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:24: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  out = s.groupby(level='Date').apply(add_ewm)\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:50: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  models = pd.Series(index=recalc_dates)\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:62: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  predictions = pd.Series(index=features.index)\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:75: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  standard_metrics = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:106: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:117: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n",
      "C:\\Users\\wston\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py:134: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  scorecard = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance    0.287870\n",
      "MAE                   2.397760\n",
      "MSE                   9.186643\n",
      "MedAE                 2.032709\n",
      "RSQ                   0.287870\n",
      "dtype: float64\n",
      "              y_pred    y_true\n",
      "Date                          \n",
      "2023-02-13 -4.810929 -5.217838\n",
      "2023-02-14  0.994094  0.670187\n",
      "2023-02-15  0.659569 -5.661687\n",
      "2023-02-16  0.265570 -0.523837\n",
      "2023-02-17 -2.415656 -1.806969\n",
      "              y_pred    y_true  sign_pred  sign_true  is_correct  \\\n",
      "Date                                                               \n",
      "2023-02-13 -4.810929 -5.217838       -1.0       -1.0           1   \n",
      "2023-02-14  0.994094  0.670187        1.0        1.0           1   \n",
      "2023-02-15  0.659569 -5.661687        1.0       -1.0           0   \n",
      "2023-02-16  0.265570 -0.523837        1.0       -1.0           0   \n",
      "2023-02-17 -2.415656 -1.806969       -1.0       -1.0           1   \n",
      "\n",
      "            is_incorrect  is_predicted    result  \n",
      "Date                                              \n",
      "2023-02-13             0             1  5.217838  \n",
      "2023-02-14             0             1  0.670187  \n",
      "2023-02-15             1             1 -5.661687  \n",
      "2023-02-16             1             1 -0.523837  \n",
      "2023-02-17             0             1  1.806969  \n",
      "year                         2010       2011       2012       2013       2014  \\\n",
      "accuracy                72.093023  70.634921  66.400000  68.650794  64.285714   \n",
      "edge                     1.978738   1.751867   1.705932   1.447559   1.177945   \n",
      "noise                    2.014822   1.951256   2.396197   2.025823   2.308127   \n",
      "y_true_chg               3.178192   3.006177   3.156944   2.917772   2.660935   \n",
      "y_pred_chg               1.506658   1.403312   1.595468   1.441491   1.556173   \n",
      "prediction_calibration   0.474061   0.466810   0.505384   0.494038   0.584822   \n",
      "capture_ratio           62.259884  58.275595  54.037443  49.611784  44.268087   \n",
      "edge_long                2.034446   1.658699   1.625203   1.095496   1.088409   \n",
      "edge_short               1.219970   2.266215   2.185252   0.280021   0.592413   \n",
      "edge_win                 3.215580   3.559357   3.845419   2.500474   2.664008   \n",
      "edge_lose               -2.510021  -1.944412  -1.975630  -3.023797  -2.397975   \n",
      "\n",
      "year                         2015       2016       2017       2018       2019  \\\n",
      "accuracy                59.920635  65.476190  72.908367  64.940239  72.222222   \n",
      "edge                     1.167563   1.303390   1.811763   1.492177   1.867879   \n",
      "noise                    2.118939   2.242322   2.219973   2.240425   2.220947   \n",
      "y_true_chg               2.669444   2.553947   2.950825   3.115662   2.798518   \n",
      "y_pred_chg               1.491707   1.529218   1.573578   1.657246   1.552149   \n",
      "prediction_calibration   0.558808   0.598767   0.533267   0.531908   0.554632   \n",
      "capture_ratio           43.738064  51.034347  61.398515  47.892766  66.745297   \n",
      "edge_long                1.140925   1.330726   1.904406   1.586533   1.770724   \n",
      "edge_short               1.240857   1.634040   1.325422   1.422873   2.022924   \n",
      "edge_win                 3.223879   3.128206   3.056610   3.555389   3.252522   \n",
      "edge_lose               -1.851495  -1.628547  -2.311776  -2.307675  -1.653210   \n",
      "\n",
      "year                         2020       2021       2022       2023  \n",
      "accuracy                70.355731  61.904762  63.745020  57.575758  \n",
      "edge                     1.635710   1.066680   1.275202   0.457647  \n",
      "noise                    2.180144   2.157738   2.179705   2.267523  \n",
      "y_true_chg               2.774742   2.675116   2.675910   2.695749  \n",
      "y_pred_chg               1.571659   1.536139   1.497822   1.557867  \n",
      "prediction_calibration   0.566416   0.574233   0.559743   0.577898  \n",
      "capture_ratio           58.949997  39.874145  47.654892  16.976611  \n",
      "edge_long                1.679347   1.032407   1.367250   0.487311  \n",
      "edge_short               1.793317   1.455190   1.210163   0.728109  \n",
      "edge_win                 3.236593   3.190950   3.107339   2.899483  \n",
      "edge_lose               -1.818968  -1.942343  -1.923561  -2.476755  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "level name symbol is not the name of the index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py\u001b[0m in \u001b[0;36m<cell line: 166>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'symbol'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_scorecard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorecard_by_symbol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10284/1177844850.py\u001b[0m in \u001b[0;36mscorecard_by_symbol\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscorecard_by_symbol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'symbol'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_scorecard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorecard_by_symbol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wston\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   8400\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8402\u001b[1;33m         return DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   8403\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8404\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wston\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m    966\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wston\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    773\u001b[0m                         \u001b[1;34mf\"level name {level} is not the name \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m                         \u001b[1;34mf\"of the {obj._get_axis_name(axis)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: level name symbol is not the name of the index"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNetCV,Lasso,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from itertools import chain\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "file1 = 'c:/users/wston/documents/python/pybuild/TSLA.csv'\n",
    "\n",
    "jump = pd.read_csv(file1)\n",
    "datetime_series = pd.DatetimeIndex(jump['Date'])\n",
    "datetime_series\n",
    "jump = jump.set_index(datetime_series)\n",
    "\n",
    "num_obs = jump[['Close']].count()\n",
    "num_obs\n",
    "\n",
    "\n",
    "def add_memory(s,n_days=50,mem_strength=0.1):\n",
    "    ''' adds autoregressive behavior to series of data'''\n",
    "    add_ewm = lambda x: (1-mem_strength)*x + mem_strength*x.ewm(n_days).mean()\n",
    "    out = s.groupby(level='Date').apply(add_ewm)\n",
    "    return out\n",
    "\n",
    "# generate feature data\n",
    "f01 = pd.Series(np.random.randn(3182),index=jump[['Close']].index)\n",
    "f01 = add_memory(f01,10,0.1)\n",
    "f02 = pd.Series(np.random.randn(3182),index=jump[['Close']].index)\n",
    "f02 = add_memory(f02,10,0.1)\n",
    "f03 = pd.Series(np.random.randn(3182),index=jump[['Close']].index)\n",
    "f03 = add_memory(f03,10,0.1)\n",
    "f04 = pd.Series(np.random.randn(3182),index=jump[['Close']].index)\n",
    "f04 = f04 # no memory\n",
    "\n",
    "features = pd.concat([f01,f02,f03,f04],axis=1)\n",
    "\n",
    "outcome =   f01 * np.linspace(0.5,1.5,3182) + \\\n",
    "            f02 * np.linspace(1.5,0.5,3182) + \\\n",
    "            f03 * pd.Series(np.sin(2*np.pi*np.linspace(0,1,3182)*2)+1,index=f03.index) + \\\n",
    "            f04 + \\\n",
    "            np.random.randn(3182) * 3 \n",
    "outcome.name = 'outcome'\n",
    "\n",
    "\n",
    "recalc_dates = features.resample('D',level='Date').mean().values[:-1]\n",
    "flat = list(chain.from_iterable(recalc_dates))\n",
    "recalc_dates = pd.Series(flat)\n",
    "models = pd.Series(index=recalc_dates)\n",
    "for date in recalc_dates:\n",
    "    X_train = features.iloc[0:3182]\n",
    "    y_train = outcome.iloc[0:3182]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    models.loc[date] = model\n",
    "\n",
    "\n",
    "begin_dates = models.index\n",
    "end_dates = models.index[1:].append(pd.to_datetime(['2099-12-31']))\n",
    "\n",
    "predictions = pd.Series(index=features.index)\n",
    "\n",
    "for i,model in enumerate(models): #loop thru each models object in collection\n",
    "    X = features.iloc[0:3182]\n",
    "    p = pd.Series(model.predict(X),index=X.index)\n",
    "    predictions.loc[X.index] = p\n",
    "\n",
    "common_idx = outcome.dropna().index.intersection(predictions.dropna().index)\n",
    "y_true = outcome[common_idx]\n",
    "y_true.name = 'y_true'\n",
    "y_pred = predictions[common_idx]\n",
    "y_pred.name = 'y_pred'\n",
    "\n",
    "standard_metrics = pd.Series()\n",
    "\n",
    "standard_metrics.loc['explained variance'] = metrics.explained_variance_score(y_true, y_pred)\n",
    "standard_metrics.loc['MAE'] = metrics.mean_absolute_error(y_true, y_pred)\n",
    "standard_metrics.loc['MSE'] = metrics.mean_squared_error(y_true, y_pred)\n",
    "standard_metrics.loc['MedAE'] = metrics.median_absolute_error(y_true, y_pred)\n",
    "standard_metrics.loc['RSQ'] = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "print(standard_metrics)\n",
    "print(pd.concat([y_pred,y_true],axis=1).tail())\n",
    "\n",
    "def make_df(y_pred,y_true):\n",
    "    y_pred.name = 'y_pred'\n",
    "    y_true.name = 'y_true'\n",
    "    \n",
    "    df = pd.concat([y_pred,y_true],axis=1)\n",
    "\n",
    "    df['sign_pred'] = df.y_pred.apply(np.sign)\n",
    "    df['sign_true'] = df.y_true.apply(np.sign)\n",
    "    df['is_correct'] = 0\n",
    "    df.loc[df.sign_pred * df.sign_true > 0 ,'is_correct'] = 1 # only registers 1 when prediction was made AND it was correct\n",
    "    df['is_incorrect'] = 0\n",
    "    df.loc[df.sign_pred * df.sign_true < 0,'is_incorrect'] = 1 # only registers 1 when prediction was made AND it was wrong\n",
    "    df['is_predicted'] = df.is_correct + df.is_incorrect\n",
    "    df['result'] = df.sign_pred * df.y_true \n",
    "    return df\n",
    "\n",
    "df = make_df(y_pred,y_true)\n",
    "print(df.dropna().tail())\n",
    "\n",
    "def calc_scorecard(df):\n",
    "    scorecard = pd.Series()\n",
    "    # building block metrics\n",
    "    scorecard.loc['accuracy'] = df.is_correct.sum()*1. / (df.is_predicted.sum()*1.)*100\n",
    "    scorecard.loc['edge'] = df.result.mean()\n",
    "    scorecard.loc['noise'] = df.y_pred.diff().abs().mean()\n",
    "    \n",
    "    return scorecard    \n",
    "\n",
    "calc_scorecard(df)\n",
    "\n",
    "def calc_scorecard(df):\n",
    "    scorecard = pd.Series()\n",
    "    # building block metrics\n",
    "    scorecard.loc['accuracy'] = df.is_correct.sum()*1. / (df.is_predicted.sum()*1.)*100\n",
    "    scorecard.loc['edge'] = df.result.mean()\n",
    "    scorecard.loc['noise'] = df.y_pred.diff().abs().mean()\n",
    "\n",
    "    # derived metrics\n",
    "    scorecard.loc['y_true_chg'] = df.y_true.abs().mean()\n",
    "    scorecard.loc['y_pred_chg'] = df.y_pred.abs().mean()\n",
    "    scorecard.loc['prediction_calibration'] = scorecard.loc['y_pred_chg']/scorecard.loc['y_true_chg']\n",
    "    scorecard.loc['capture_ratio'] = scorecard.loc['edge']/scorecard.loc['y_true_chg']*100\n",
    "\n",
    "    return scorecard    \n",
    "\n",
    "calc_scorecard(df)\n",
    "\n",
    "def calc_scorecard(df):\n",
    "    scorecard = pd.Series()\n",
    "    # building block metrics\n",
    "    scorecard.loc['accuracy'] = df.is_correct.sum()*1. / (df.is_predicted.sum()*1.)*100\n",
    "    scorecard.loc['edge'] = df.result.mean()\n",
    "    scorecard.loc['noise'] = df.y_pred.diff().abs().mean()\n",
    "\n",
    "    # derived metrics\n",
    "    scorecard.loc['y_true_chg'] = df.y_true.abs().mean()\n",
    "    scorecard.loc['y_pred_chg'] = df.y_pred.abs().mean()\n",
    "    scorecard.loc['prediction_calibration'] = scorecard.loc['y_pred_chg']/scorecard.loc['y_true_chg']\n",
    "    scorecard.loc['capture_ratio'] = scorecard.loc['edge']/scorecard.loc['y_true_chg']*100\n",
    "\n",
    "    # metrics for a subset of predictions\n",
    "    scorecard.loc['edge_long'] = df[df.sign_pred == 1].result.mean()  - df.y_true.mean()\n",
    "    scorecard.loc['edge_short'] = df[df.sign_pred == -1].result.mean()  - df.y_true.mean()\n",
    "\n",
    "    scorecard.loc['edge_win'] = df[df.is_correct == 1].result.mean()  - df.y_true.mean()\n",
    "    scorecard.loc['edge_lose'] = df[df.is_incorrect == 1].result.mean()  - df.y_true.mean()\n",
    "\n",
    "    return scorecard    \n",
    "\n",
    "calc_scorecard(df)\n",
    "\n",
    "def scorecard_by_year(df):\n",
    "    df['year'] = df.index.get_level_values('Date').year\n",
    "    return df.groupby('year').apply(calc_scorecard).T\n",
    "\n",
    "print(scorecard_by_year(df))\n",
    "\n",
    "def scorecard_by_symbol(df):\n",
    "    return df.groupby(level='symbol').apply(calc_scorecard).T\n",
    "\n",
    "print(scorecard_by_symbol(df))\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,outcome,test_size=0.20,shuffle=False)\n",
    "\n",
    "model1 = LinearRegression().fit(X_train,y_train)\n",
    "model1_train = pd.Series(model1.predict(X_train),index=X_train.index)\n",
    "model1_test = pd.Series(model1.predict(X_test),index=X_test.index)\n",
    "\n",
    "model2 = RandomForestRegressor().fit(X_train,y_train)\n",
    "model2_train = pd.Series(model2.predict(X_train),index=X_train.index)\n",
    "model2_test = pd.Series(model2.predict(X_test),index=X_test.index)\n",
    "\n",
    "# create dataframes for each \n",
    "model1_train_df = make_df(model1_train,y_train)\n",
    "model1_test_df = make_df(model1_test,y_test)\n",
    "model2_train_df = make_df(model2_train,y_train)\n",
    "model2_test_df = make_df(model2_test,y_test)\n",
    "\n",
    "s1 = calc_scorecard(model1_train_df)\n",
    "s1.name = 'model1_train'\n",
    "s2 = calc_scorecard(model1_test_df)\n",
    "s2.name = 'model1_test'\n",
    "s3 = calc_scorecard(model2_train_df)\n",
    "s3.name = 'model2_train'\n",
    "s4 = calc_scorecard(model2_test_df)\n",
    "s4.name = 'model2_test'\n",
    "\n",
    "print(pd.concat([s1,s2,s3,s4],axis=1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f30b61588f9226991898c492d0623badcbd51d114ede6adcda3f93366c18369"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
